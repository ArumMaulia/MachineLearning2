{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4e6c6a-941d-43d2-9cf4-a6ed7db684cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c69bff-b757-4b67-967a-492ada65fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize_wrapper(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "033da15e-1a86-4f6a-87a6-f786ba9a7b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teks_nltk = word_tokenize_wrapper('Yahya beserta teman-teman TK suka melihat lumba-lumba di Batang Dolphin Center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6eabde5-30cf-40ec-83c9-fea4786c7d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yahya',\n",
       " 'beserta',\n",
       " 'teman-teman',\n",
       " 'TK',\n",
       " 'suka',\n",
       " 'melihat',\n",
       " 'lumba-lumba',\n",
       " 'di',\n",
       " 'Batang',\n",
       " 'Dolphin',\n",
       " 'Center']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teks_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b232da-5c9e-43c8-bdee-3281c92ba1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.id import Indonesian\n",
    "import spacy\n",
    "\n",
    "nlp = Indonesian()  # use directly\n",
    "nlp = spacy.blank('id')  # blank instance'\n",
    "Teks = nlp('Yahya beserta teman-teman TK suka melihat lumba-lumba di Batang Dolphin Center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5281b22a-fb1e-427d-8eec-369208faf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token_kata = [token.text for token in Teks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367bfb3c-2e48-4d08-9a01-92e49b76c7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yahya',\n",
       " 'beserta',\n",
       " 'teman-teman',\n",
       " 'TK',\n",
       " 'suka',\n",
       " 'melihat',\n",
       " 'lumba-lumba',\n",
       " 'di',\n",
       " 'Batang',\n",
       " 'Dolphin',\n",
       " 'Center']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token_kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10cb54d9-493f-4559-b728-e43d0a949a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "609dab8f-ded9-44ee-a706-7823d6a217dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a135ff1a-d0b4-446c-96a3-44c542af85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset_Sentimen_Emosi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2f488f-e52b-4769-8ded-2a2d9b089841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Emosi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentimen  Emosi\n",
       "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0      1\n",
       "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0     -1\n",
       "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0      1\n",
       "3            Covid belum nyampe prigen mbak hmm hoax       0.0     -2\n",
       "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0     -2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0478b0c0-fc14-4a1b-ba13-f18133b14997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Emosi'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453899ca-3271-49ed-b92c-869990c16bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Seluruh negara di dunia mengalami masa sulit k...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Setelah covid dan skripsi disaster selesai, ma...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Malam ini!! Projek \"BENDA BOLEH BINCANG\" 9 mal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Pontang - panting di koyak covid 19</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Masalahnya sekarang isu jangkitan covid. Alaaa...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>904 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet  Sentimen\n",
       "0    Cegah mata rantai Covid-19,mari kita dirumah s...       1.0\n",
       "1    aku mohon yaAllah semoga wabah covid-19 menghi...       1.0\n",
       "2    Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0\n",
       "3              Covid belum nyampe prigen mbak hmm hoax       0.0\n",
       "4    Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0\n",
       "..                                                 ...       ...\n",
       "899  Seluruh negara di dunia mengalami masa sulit k...       1.0\n",
       "900  Setelah covid dan skripsi disaster selesai, ma...       1.0\n",
       "901  Malam ini!! Projek \"BENDA BOLEH BINCANG\" 9 mal...       0.0\n",
       "902                Pontang - panting di koyak covid 19      -1.0\n",
       "903  Masalahnya sekarang isu jangkitan covid. Alaaa...      -1.0\n",
       "\n",
       "[904 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8562f22-9c9c-432d-8a82-6796f1f03c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 904 entries, 0 to 903\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet     904 non-null    object \n",
      " 1   Sentimen  903 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 14.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a30a2e1d-1237-40d2-96cd-6a4333e090c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARUM MAULIA\\anaconda3\\Lib\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARUM MAULIA\\anaconda3\\Lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    #annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",'emphasis', 'censored'},\n",
    "    annotate={\"hashtag\"},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfb14ea-fd86-4d58-af6d-2bc52af02951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bersih_data(text):\n",
    "    return \" \".join(text_processor.pre_process_doc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab53a1c1-b234-4ccc-b64c-325685085e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_ascii(text):\n",
    "    return text.encode('ascii', 'replace').decode('ascii')\n",
    "\n",
    "def remove_space_alzami(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def remove_emoji_alzami(text):\n",
    "    return ' '.join(re.sub(\"([x#][A-Za-z0-9]+)\",\" \", text).split())\n",
    "\n",
    "def remove_tab(text):\n",
    "    return text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "\n",
    "def remove_tab2(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_rt(text):\n",
    "    return text.replace('rt',\" \")\n",
    "\n",
    "def remove_mention(text):\n",
    "    return ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "\n",
    "def remove_incomplete_url(text):\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def change_stripe(text):\n",
    "    return text.replace('-',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\"_\", \"\") # don't remove hyphens\n",
    "    pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "    return re.sub(pattern, \"\", text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dbade11-4f05-4158-84e0-b194b773f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_number_eks(text):\n",
    "    return text.replace('<number>',\" \")\n",
    "\n",
    "def remove_angka(text):\n",
    "    return re.sub(r\"\\d+\", \"\", text) \n",
    "\n",
    "def remove_URL_eks(text):\n",
    "    return text.replace('URL',\" \").replace('url',\" \")\n",
    "\n",
    "def space_punctuation(text):\n",
    "    return re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de7d5c33-a739-4ed7-a4c5-e5cd188d2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "final_string = []\n",
    "s = \"\"\n",
    "for text in df['Tweet'].values:\n",
    "    filteredSentence = []\n",
    "    EachReviewText = \"\"\n",
    "    proc = lower(text)\n",
    "    proc = change_stripe(text)\n",
    "    proc = remove_emoji_alzami(proc)\n",
    "    proc = remove_tab(proc)\n",
    "    proc = remove_tab2(proc)\n",
    "    proc = non_ascii(proc)\n",
    "    proc = remove_incomplete_url(proc)\n",
    "    proc = remove_excessive_dot(proc)\n",
    "    proc = remove_whitespace_LT(proc)\n",
    "    proc = remove_whitespace_multiple(proc)\n",
    "    proc = remove_single_char(proc)\n",
    "    proc = space_punctuation(proc)\n",
    "    proc = remove_punctuation(proc)\n",
    "    proc = remove_space_alzami(proc)\n",
    "    proc = bersih_data(proc)\n",
    "    #proc = remove_rt(proc)\n",
    "    proc = remove_number_eks(proc)\n",
    "    proc = remove_angka(proc) \n",
    "    proc = remove_URL_eks(proc)\n",
    "    EachReviewText = proc\n",
    "    final_string.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33bf3bd7-2b9a-4a5e-9802-974c62ba47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"step01\"] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e20d85b-9e64-4eff-88c2-9272673b420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah mata rantai covid   mari kita dirumah sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid   menghil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pikir2 balik byk mnde plk nk setelkn lepas covid.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pikir balik byk mnde plk nk setelkn lepas covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Selamat pagi, hari jum'at. Jum'at keempat di k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>selamat pagi hari jumat jumat keempat di kala ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hikmah di balik musibah covid-19, smg para pej...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hikmah di balik musibah covid   smg para pejab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cegah covid-19 beserta jajaran Polsek Kuranji ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah covid   beserta jajaran polsek kuranji m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ya Allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ya allah kami memohon pada mu perkenankanlah d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentimen  \\\n",
       "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0   \n",
       "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0   \n",
       "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0   \n",
       "3            Covid belum nyampe prigen mbak hmm hoax       0.0   \n",
       "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0   \n",
       "5  Pikir2 balik byk mnde plk nk setelkn lepas covid.       0.0   \n",
       "6  Selamat pagi, hari jum'at. Jum'at keempat di k...       1.0   \n",
       "7  Hikmah di balik musibah covid-19, smg para pej...       1.0   \n",
       "8  Cegah covid-19 beserta jajaran Polsek Kuranji ...       1.0   \n",
       "9  Ya Allah kami memohon pada mu perkenankanlah d...       1.0   \n",
       "\n",
       "                                              step01  \n",
       "0  cegah mata rantai covid   mari kita dirumah sa...  \n",
       "1  aku mohon yaallah semoga wabah covid   menghil...  \n",
       "2  pemprov papua naikkan status jadi tanggap daru...  \n",
       "3            covid belum nyampe prigen mbak hmm hoax  \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...  \n",
       "5    pikir balik byk mnde plk nk setelkn lepas covid  \n",
       "6  selamat pagi hari jumat jumat keempat di kala ...  \n",
       "7  hikmah di balik musibah covid   smg para pejab...  \n",
       "8  cegah covid   beserta jajaran polsek kuranji m...  \n",
       "9  ya allah kami memohon pada mu perkenankanlah d...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f388ddc-049d-4654-8830-5532f114814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 904 entries, 0 to 903\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet     904 non-null    object \n",
      " 1   Sentimen  903 non-null    float64\n",
      " 2   step01    904 non-null    object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 21.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dee6854c-8c8e-4089-af1b-6c7a2f61d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hapus = df[~df['step01'].str.contains(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db13c147-35e3-4456-8981-f65d13c3f326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1 entries, 78 to 78\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet     1 non-null      object \n",
      " 1   Sentimen  1 non-null      float64\n",
      " 2   step01    1 non-null      object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 32.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_hapus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c4a9247-8267-4b20-b114-2816c73278d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>covid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tweet  Sentimen step01\n",
       "78  covid       0.0  covid"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hapus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e276e3ce-b44b-42e5-8a00-563d01ba3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[~df.isin(df_hapus)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d76e7c21-0849-408c-920e-cc19250abf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 902 entries, 0 to 903\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet     902 non-null    object \n",
      " 1   Sentimen  902 non-null    float64\n",
      " 2   step01    902 non-null    object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 28.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c11dcf32-2c44-428e-9984-3e51e17bd76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah mata rantai covid   mari kita dirumah sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid   menghil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Seluruh negara di dunia mengalami masa sulit k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>seluruh negara di dunia mengalami masa sulit k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Setelah covid dan skripsi disaster selesai, ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>setelah covid dan skripsi disaster selesai mau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Malam ini!! Projek \"BENDA BOLEH BINCANG\" 9 mal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>malam ini projek benda boleh bincang   malam d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Pontang - panting di koyak covid 19</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>pontang panting di koyak covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Masalahnya sekarang isu jangkitan covid. Alaaa...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>masalahnya sekarang isu jangkitan covid alaaaa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>902 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet  Sentimen  \\\n",
       "0    Cegah mata rantai Covid-19,mari kita dirumah s...       1.0   \n",
       "1    aku mohon yaAllah semoga wabah covid-19 menghi...       1.0   \n",
       "2    Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0   \n",
       "3              Covid belum nyampe prigen mbak hmm hoax       0.0   \n",
       "4    Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0   \n",
       "..                                                 ...       ...   \n",
       "899  Seluruh negara di dunia mengalami masa sulit k...       1.0   \n",
       "900  Setelah covid dan skripsi disaster selesai, ma...       1.0   \n",
       "901  Malam ini!! Projek \"BENDA BOLEH BINCANG\" 9 mal...       0.0   \n",
       "902                Pontang - panting di koyak covid 19      -1.0   \n",
       "903  Masalahnya sekarang isu jangkitan covid. Alaaa...      -1.0   \n",
       "\n",
       "                                                step01  \n",
       "0    cegah mata rantai covid   mari kita dirumah sa...  \n",
       "1    aku mohon yaallah semoga wabah covid   menghil...  \n",
       "2    pemprov papua naikkan status jadi tanggap daru...  \n",
       "3              covid belum nyampe prigen mbak hmm hoax  \n",
       "4    nyuruh orang pintar lu aja togog itu kerumunan...  \n",
       "..                                                 ...  \n",
       "899  seluruh negara di dunia mengalami masa sulit k...  \n",
       "900  setelah covid dan skripsi disaster selesai mau...  \n",
       "901  malam ini projek benda boleh bincang   malam d...  \n",
       "902                   pontang panting di koyak covid    \n",
       "903  masalahnya sekarang isu jangkitan covid alaaaa...  \n",
       "\n",
       "[902 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa1ce1f1-765b-419d-8734-b0ebed2e8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a304cce-a8d7-488e-9533-41fa16b4e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize_wrapper(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cc1ba9f-44b1-477b-92c7-83def4341027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['tokens'] = df['step01'].apply(word_tokenize_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1662a17-6902-4126-ba04-7ca2badb802e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah mata rantai covid   mari kita dirumah sa...</td>\n",
       "      <td>[cegah, mata, rantai, covid, mari, kita, dirum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid   menghil...</td>\n",
       "      <td>[aku, mohon, yaallah, semoga, wabah, covid, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "      <td>[pemprov, papua, naikkan, status, jadi, tangga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>[covid, belum, nyampe, prigen, mbak, hmm, hoax]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "      <td>[nyuruh, orang, pintar, lu, aja, togog, itu, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pikir2 balik byk mnde plk nk setelkn lepas covid.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pikir balik byk mnde plk nk setelkn lepas covid</td>\n",
       "      <td>[pikir, balik, byk, mnde, plk, nk, setelkn, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Selamat pagi, hari jum'at. Jum'at keempat di k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>selamat pagi hari jumat jumat keempat di kala ...</td>\n",
       "      <td>[selamat, pagi, hari, jumat, jumat, keempat, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hikmah di balik musibah covid-19, smg para pej...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hikmah di balik musibah covid   smg para pejab...</td>\n",
       "      <td>[hikmah, di, balik, musibah, covid, smg, para,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cegah covid-19 beserta jajaran Polsek Kuranji ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah covid   beserta jajaran polsek kuranji m...</td>\n",
       "      <td>[cegah, covid, beserta, jajaran, polsek, kuran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ya Allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ya allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>[ya, allah, kami, memohon, pada, mu, perkenank...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentimen  \\\n",
       "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0   \n",
       "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0   \n",
       "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0   \n",
       "3            Covid belum nyampe prigen mbak hmm hoax       0.0   \n",
       "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0   \n",
       "5  Pikir2 balik byk mnde plk nk setelkn lepas covid.       0.0   \n",
       "6  Selamat pagi, hari jum'at. Jum'at keempat di k...       1.0   \n",
       "7  Hikmah di balik musibah covid-19, smg para pej...       1.0   \n",
       "8  Cegah covid-19 beserta jajaran Polsek Kuranji ...       1.0   \n",
       "9  Ya Allah kami memohon pada mu perkenankanlah d...       1.0   \n",
       "\n",
       "                                              step01  \\\n",
       "0  cegah mata rantai covid   mari kita dirumah sa...   \n",
       "1  aku mohon yaallah semoga wabah covid   menghil...   \n",
       "2  pemprov papua naikkan status jadi tanggap daru...   \n",
       "3            covid belum nyampe prigen mbak hmm hoax   \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...   \n",
       "5    pikir balik byk mnde plk nk setelkn lepas covid   \n",
       "6  selamat pagi hari jumat jumat keempat di kala ...   \n",
       "7  hikmah di balik musibah covid   smg para pejab...   \n",
       "8  cegah covid   beserta jajaran polsek kuranji m...   \n",
       "9  ya allah kami memohon pada mu perkenankanlah d...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [cegah, mata, rantai, covid, mari, kita, dirum...  \n",
       "1  [aku, mohon, yaallah, semoga, wabah, covid, me...  \n",
       "2  [pemprov, papua, naikkan, status, jadi, tangga...  \n",
       "3    [covid, belum, nyampe, prigen, mbak, hmm, hoax]  \n",
       "4  [nyuruh, orang, pintar, lu, aja, togog, itu, k...  \n",
       "5  [pikir, balik, byk, mnde, plk, nk, setelkn, le...  \n",
       "6  [selamat, pagi, hari, jumat, jumat, keempat, d...  \n",
       "7  [hikmah, di, balik, musibah, covid, smg, para,...  \n",
       "8  [cegah, covid, beserta, jajaran, polsek, kuran...  \n",
       "9  [ya, allah, kami, memohon, pada, mu, perkenank...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "798a99f6-b269-4e95-9428-05a4c12bbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_word = pd.read_csv('kamus_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43858364-14c0-4018-b385-3280021adae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARUM MAULIA\\AppData\\Local\\Temp\\ipykernel_15844\\2408214049.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[0] not in normalized_word_dict:\n",
      "C:\\Users\\ARUM MAULIA\\AppData\\Local\\Temp\\ipykernel_15844\\2408214049.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  normalized_word_dict[row[0]] = row[1]\n"
     ]
    }
   ],
   "source": [
    "normalized_word_dict = {}\n",
    "\n",
    "for index, row in normalized_word.iterrows():\n",
    "    if row[0] not in normalized_word_dict:\n",
    "        normalized_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalized_word_dict[term] if term in normalized_word_dict else term for term in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17de5bbf-70cb-49aa-b4a3-de957b9b654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['final_tokens'] = df_new['tokens'].apply(normalized_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4a16191-e0bd-442a-be0c-56482f9431b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "final_string_tokens = []\n",
    "for text in df_new['final_tokens'].values:\n",
    "    EachReviewText = \"\"\n",
    "    EachReviewText = ' '.join(text)\n",
    "    final_string_tokens.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bef149f-71b3-4055-b693-15f52a4b1c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"step02\"] = final_string_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec04489c-4e09-43e6-a840-29f8bfa03eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "      <th>final_tokens</th>\n",
       "      <th>step02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah mata rantai covid   mari kita dirumah sa...</td>\n",
       "      <td>[cegah, mata, rantai, covid, mari, kita, dirum...</td>\n",
       "      <td>[cegah, mata, rantai, covid, mari, kita, dirum...</td>\n",
       "      <td>cegah mata rantai covid mari kita dirumah saja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid   menghil...</td>\n",
       "      <td>[aku, mohon, yaallah, semoga, wabah, covid, me...</td>\n",
       "      <td>[aku, mohon, yaallah, semoga, wabah, covid, me...</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid menghilan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "      <td>[pemprov, papua, naikkan, status, jadi, tangga...</td>\n",
       "      <td>[pemprov, papua, naikkan, status, jadi, tangga...</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>[covid, belum, nyampe, prigen, mbak, hmm, hoax]</td>\n",
       "      <td>[covid, belum, nyampe, prigen, mbak, hmm, hoax]</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "      <td>[nyuruh, orang, pintar, lu, aja, togog, itu, k...</td>\n",
       "      <td>[nyuruh, orang, pintar, lu, aja, togog, itu, k...</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pikir2 balik byk mnde plk nk setelkn lepas covid.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pikir balik byk mnde plk nk setelkn lepas covid</td>\n",
       "      <td>[pikir, balik, byk, mnde, plk, nk, setelkn, le...</td>\n",
       "      <td>[pikir, balik, byk, mnde, plk, nk, setelkn, le...</td>\n",
       "      <td>pikir balik byk mnde plk nk setelkn lepas covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Selamat pagi, hari jum'at. Jum'at keempat di k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>selamat pagi hari jumat jumat keempat di kala ...</td>\n",
       "      <td>[selamat, pagi, hari, jumat, jumat, keempat, d...</td>\n",
       "      <td>[selamat, pagi, hari, jumat, jumat, keempat, d...</td>\n",
       "      <td>selamat pagi hari jumat jumat keempat di kala ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hikmah di balik musibah covid-19, smg para pej...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hikmah di balik musibah covid   smg para pejab...</td>\n",
       "      <td>[hikmah, di, balik, musibah, covid, smg, para,...</td>\n",
       "      <td>[hikmah, di, balik, musibah, covid, smg, para,...</td>\n",
       "      <td>hikmah di balik musibah covid smg para pejabat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cegah covid-19 beserta jajaran Polsek Kuranji ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah covid   beserta jajaran polsek kuranji m...</td>\n",
       "      <td>[cegah, covid, beserta, jajaran, polsek, kuran...</td>\n",
       "      <td>[cegah, covid, beserta, jajaran, polsek, kuran...</td>\n",
       "      <td>cegah covid beserta jajaran polsek kuranji mel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ya Allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ya allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>[ya, allah, kami, memohon, pada, mu, perkenank...</td>\n",
       "      <td>[ya, allah, kami, memohon, pada, mu, perkenank...</td>\n",
       "      <td>ya allah kami memohon pada mu perkenankanlah d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentimen  \\\n",
       "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0   \n",
       "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0   \n",
       "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0   \n",
       "3            Covid belum nyampe prigen mbak hmm hoax       0.0   \n",
       "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0   \n",
       "5  Pikir2 balik byk mnde plk nk setelkn lepas covid.       0.0   \n",
       "6  Selamat pagi, hari jum'at. Jum'at keempat di k...       1.0   \n",
       "7  Hikmah di balik musibah covid-19, smg para pej...       1.0   \n",
       "8  Cegah covid-19 beserta jajaran Polsek Kuranji ...       1.0   \n",
       "9  Ya Allah kami memohon pada mu perkenankanlah d...       1.0   \n",
       "\n",
       "                                              step01  \\\n",
       "0  cegah mata rantai covid   mari kita dirumah sa...   \n",
       "1  aku mohon yaallah semoga wabah covid   menghil...   \n",
       "2  pemprov papua naikkan status jadi tanggap daru...   \n",
       "3            covid belum nyampe prigen mbak hmm hoax   \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...   \n",
       "5    pikir balik byk mnde plk nk setelkn lepas covid   \n",
       "6  selamat pagi hari jumat jumat keempat di kala ...   \n",
       "7  hikmah di balik musibah covid   smg para pejab...   \n",
       "8  cegah covid   beserta jajaran polsek kuranji m...   \n",
       "9  ya allah kami memohon pada mu perkenankanlah d...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [cegah, mata, rantai, covid, mari, kita, dirum...   \n",
       "1  [aku, mohon, yaallah, semoga, wabah, covid, me...   \n",
       "2  [pemprov, papua, naikkan, status, jadi, tangga...   \n",
       "3    [covid, belum, nyampe, prigen, mbak, hmm, hoax]   \n",
       "4  [nyuruh, orang, pintar, lu, aja, togog, itu, k...   \n",
       "5  [pikir, balik, byk, mnde, plk, nk, setelkn, le...   \n",
       "6  [selamat, pagi, hari, jumat, jumat, keempat, d...   \n",
       "7  [hikmah, di, balik, musibah, covid, smg, para,...   \n",
       "8  [cegah, covid, beserta, jajaran, polsek, kuran...   \n",
       "9  [ya, allah, kami, memohon, pada, mu, perkenank...   \n",
       "\n",
       "                                        final_tokens  \\\n",
       "0  [cegah, mata, rantai, covid, mari, kita, dirum...   \n",
       "1  [aku, mohon, yaallah, semoga, wabah, covid, me...   \n",
       "2  [pemprov, papua, naikkan, status, jadi, tangga...   \n",
       "3    [covid, belum, nyampe, prigen, mbak, hmm, hoax]   \n",
       "4  [nyuruh, orang, pintar, lu, aja, togog, itu, k...   \n",
       "5  [pikir, balik, byk, mnde, plk, nk, setelkn, le...   \n",
       "6  [selamat, pagi, hari, jumat, jumat, keempat, d...   \n",
       "7  [hikmah, di, balik, musibah, covid, smg, para,...   \n",
       "8  [cegah, covid, beserta, jajaran, polsek, kuran...   \n",
       "9  [ya, allah, kami, memohon, pada, mu, perkenank...   \n",
       "\n",
       "                                              step02  \n",
       "0  cegah mata rantai covid mari kita dirumah saja...  \n",
       "1  aku mohon yaallah semoga wabah covid menghilan...  \n",
       "2  pemprov papua naikkan status jadi tanggap daru...  \n",
       "3            covid belum nyampe prigen mbak hmm hoax  \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...  \n",
       "5    pikir balik byk mnde plk nk setelkn lepas covid  \n",
       "6  selamat pagi hari jumat jumat keempat di kala ...  \n",
       "7  hikmah di balik musibah covid smg para pejabat...  \n",
       "8  cegah covid beserta jajaran polsek kuranji mel...  \n",
       "9  ya allah kami memohon pada mu perkenankanlah d...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b781aa8c-ffda-413d-a68b-71046ed6d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_dataset2.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431f1c6-d82a-4732-9202-dd97f06fbb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
